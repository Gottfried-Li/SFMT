%%%%%%%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your contribution to a "contributed book"
%
% "contributed book"
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{svmult}

\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{amssymb}
\usepackage{color}
\usepackage{url}
\usepackage{verbatim}
\usepackage[dvipdfm]{graphicx} % add

%\usepackage{makeidx}         % allows index generation
\usepackage{graphicx}        % standard LaTeX graphics tool
                             % when including figure files
%\makeindex             % used for the subject index
                       % please use the style sprmidx.sty with
                       % your makeindex program

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{conjecture}[theorem]{Conjecture}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newdef{definition}[theorem]{Definition}
%\newdef{remark}[theorem]{Remark}

% \def\F2{{\mathbb F}_2}
% \def\wt{{\rm wt}}
% \def\wo{{\rm wt}_o}
% \def\wf{{\rm wt}_f}
% \def\UL{{\rm ul}}
% \def\bx{{{\mathbf x}}}
% \def\by{{{\mathbf y}}}
% \def\bz{{{\mathbf z}}}
% \def\bw{{{\mathbf w}}}
% \def\bu{{{\mathbf u}}}
% \def\im{{\mathrm{Im}}}
% \def\ker{{\mathrm{Ker}}}
% \def\id{{\mathrm{Id}}}
% \def\tr{{\mathrm{tr}}}

\def\bbf2{\ifmmode\mathbb{F}_2\else$\mathbb{F}_2$\fi}%
%\newcommand{\bbf2}{{\ifmmode \mathbb{F}_2 \else $\mathbb{F}_2$ \fi}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%\newcommand{\bbf2}{\ifmmode \mathbb{F}_2 \else $\mathbb{F}_2$ \fi}
\newcommand{\mmod}{\textrm{mod}\,}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\title*{Ultra-Fast Low-Discrepancy Points}
%\titlerunning{Fast Points}
%\title*{A uniform real random number generator obeying the IEEE 754
%  format using an affine transition}
\title*{A PRNG specialized in double precision floating point numbers
  using an affine transition}

\titlerunning{A PRNG specialized in double precision floating point numbers}

% \author{
% Usain Bolt\inst{1}\and
% Michael Phelps\inst{2}
% }
\author{Mutsuo Saito\inst{1}\and
Makoto Matsumoto\inst{2}}
% Use \authorrunning{Short Title} for an abbreviated version...
%
% \institute{
% Departement of Superhumans \\
% Lightning Yellow High School\\
% Kingston, Jamaica\\
% \url{http://en.wikipedia.org/wiki/Usain_Bolt}
% \and
% Deep Blue Swimming Pool \\
% University of Baltimore, USA \\
% \url{http://en.wikipedia.org/wiki/Michael_Phelps}
% }
\institute{
Dept.\ of Math.\ Hiroshima University
\texttt{saito@math.sci.hiroshima-u.ac.jp}
\and 
Dept.\ of Math.\ Hiroshima University
\texttt{m-mat@math.sci.hiroshima-u.ac.jp}
}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            
\begin{abstract} 
  We propose a pseudorandom number generator (PRNG) specialized to
  generate double precision floating point numbers in IEEE 754 format.

  The generator makes pseudorandom 52-bit patterns supplemented
  by a constant most significant 12-bit (sign and exponent), so 
  that the concatenated 64-bit represents a floating
  point number in the range [1,2) obeying the IEEE 754 format.

  Many PRNGs use a linear transition function over the two element 
  field $\mathbb{F}_2$, but here we use an affine transition function,
  namely the state vector $x$ is mapped to the next state $Ax+c$,
  where $A$ is an $\mathbb{F}_2$ matrix, and $c$ is a constant vector. 
  The existence of $c$ is due to the constant 12-bit.
  %This constant
  %is necessary to fix the most significant bits.
  By a slight modification of the classical linear case,
  one can obtain the (lower bound of) period and the dimension of
  equi-distribution of the generator.

  Using SIMD instruction set, we designed dSFMT (double precision floating
  point SFMT), which generates two floating point numbers of 52-bit precision
  at one recursion.
%  The generation speed is almost same or faster than Mersenne Twister's
%  double precision floating point number generation from 32-bit integer.
  The generation speed is faster than Mersenne Twister's
  floating point number generation from 32-bit integer
  that has 32-bit precision only.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section {Introduction}
\label{sec:intro}

Recently, the scale of simulations is getting larger, and faster
pseudorandom number generators (PRNGs) are required. The power of CPUs
for usual personal computers are now sufficiently strong for such
purposes, and the necessity of efficient PRNGs for CPUs on PCs is
increasing.

We proposed a fast pseudorandom number generator, SIMD-oriented Fast
Mersenne Twister\cite{SFMT} (SFMT) in MCQMC 2006.  SFMT is a successor
of Mersenne Twister\cite{MT} (MT) and faster than the original and has
better equidistribution property.

SFMT is based on a Single Instruction Multiple Data\cite{wiki:SIMD}
(SIMD) feature of recent CPUs. SIMD processes 128-bit data
at one time, and the design of SFMT fits to SIMD.
We also proposed another speed up: block generation 
procedure which returns a large block of pseudorandom numbers by one
call.  
%Both of them have been widely known as a technique of speed
%up, and can be seen as a speed-up by a restriction/specialization.

We are interested in scientific simulations, and most scientific
Monte-Carlo simulation requires great deal of floating point
pseudorandom numbers. In this article, we describe a faster PRNG
specialized in generating floating point numbers.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generating floating point numbers}
\label{sec:floating}

Usually, floating point pseudorandom numbers are obtained by
converting integer pseudorandom numbers. 
One may consider recursion in floating
point numbers for PRNG, but it accumulates approximation errors.
Since the rounding-off is not standardized, the generated
sequence often depends on CPUs. 
Thus, usual PRNGs generate integer random numbers by integer recursion
(which is exact and fast) and converts them 
to floating point numbers by multiplying a constant.
However, this method requires a conversion from an integer to
a floating point number, which is rather slow.

A faster conversion is given by using bit operations on integer
number to fit to IEEE 754 floating point format. For example, in C
language, conversion of a 64-bit integer \texttt{x} to 
the corresponding double precision floating point number \texttt{y} can be done by:
\begin{verbatim}
   x = (x >> 12) | 0x3FF0000000000000ULL;
   y = *((double *)&x);
\end{verbatim}, more appropriate way in C is to use \textbf{union}.
The first line shifts \texttt{x} to the right by 12 bits,
and set the 12 most significant bits (MSBs) to the constant.
These 12 bits specify the sign and the exponent, and thus, if the 64-bit
is regarded as a floating point number by the second line, then 
it gives a floating point number normalized in $[1,2)$.

This method was known at least in 1997. Anger Fog used this method in
his open source library\cite{web:Fog}.  Others seemed to find this method
independently around the year.

Another method is to convert the unsigned integer to 
a signed integer with same number of bits,
and then to a (signed) floating point number.
This method is often fast, because converting unsigned
integer to floating point is slower than signed integer 
(hardware converter is sometimes designated for signed integer,
cf. \cite{doornik}). 

Thinking about \bbf2-linear generator like MT, its output is 
a vector with components in \bbf2, considered as
a binary integer. In this article, we propose an \bbf2-linear 
(more exactly, \bbf2-affine) generator whose
output vectors are regarded as representations 
of floating point numbers in IEEE 754 format. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{IEEE double precision floating point format}
\label{sec:ieee}

IEEE Standard for Binary Floating-Point Arithmetic (ANSI/IEEE Std
754-2008)\cite{ieee754} is the most widely-used standard for
floating-point numbers. The standard was defined in 1985 and revised
in 2008. Here we treat the 64-bit binary format defined in 1985,
which is equally valid in the 2008 standard. Figure~\ref{fig:ieee}
shows the 64-bit binary format, which has 1 sign bit, 11 exponent bits
and 52 fraction bits.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.7\linewidth]{ieee.pdf}
    \caption{Sign bit, exponent bits and fraction bits of double
      precision floating point number.}
    \label{fig:ieee}
  \end{center}
\end{figure}

Table~\ref{tab:ieee} shows how floating point numbers are described in
the format. Usually, numbers are represented as a normalized
number as in the last column. In a normalized number, 
the 52-bit fraction part \texttt{xxx}$\ldots$ is interpreted
as a binary floating number 1.\texttt{xxx}$\ldots$, which 
is denoted by $f$. Thus, $1 \le f < 2$.
The exponent part $e$ has an offset 1023, 
and the total 64-bit of the format represents the number
$\pm f \times 2^{e - 1023}$. 

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|l|c|c|c|} \hline
      & exponent & fraction & represented number \\ \hline
      zero & 0 & 0 & $\pm 0$ \\ \hline
      denormalized number & 0 & $\neq$ 0 
      & $\pm 0.\texttt{xxxx} \times 2^{-1022}$ \\ 
      \hline
      $\infty$ & 2047 & 0 & $\pm\infty$ \\ \hline
      NaN & 2047 & $\neq$ 0 & Not a Number \\ \hline
      normalized number & 
      other & any & 
      $\pm 1.\texttt{xxxxx} \times 2^{e - 1023}$ \\ \hline
    \end{tabular}
    \caption{Description of double precision floating point
      numbers. \texttt{xxxx} denotes the bit pattern of the fraction part.}
    \label{tab:ieee}
  \end{center}
\end{table}

If sign bit is 0 and exponent part (11 bit) is 0x3ff,
%then the format represent a normalized number in the range [1, 2).
then the number $r$ represented by the format is in the range $1 \le r
< 2$. Hence, we decided to design a PRNG whose output is uniformly
distributed in the range [1, 2).

Most of application programs need PRNG in the range $[0,1)$
or $(0,1]$, but the conversion from $[1,2)$ is just a simple
subtraction between floating points, hence
it is fast. Our generator also supports the range $(0,1)$
by setting the least significant bit of the
fraction part, which is a little bit slower.

Note that when one uses the generated random number $r$
as in $\sin(2 \pi r)$, then $[0,1)$ and $[1,2)$ give the same distribution.

%\begin{note}
%  As described above, 
%  a normalized number has 53-bit precision though it has only 52-bit
%  fraction part. On the other hand, our generator has 52-bit precision
%  because the exponent part is fixed.
%\end{note}
%  I (Makoto) can guess what is meant, but I feel it inappropriate
%  here, since the definition of ``precision'' is unclear.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Theoretical base}
\label{sec:base}

Our proposal is based on Linear Feedback Shift Register (LFSR),
with additional memory called `lung' (LFSR with
lung is called Pulmonary LFSR).

%%%%%%%%%%%%%%%%%%%%
\subsection{LFSR, Pulmonary LFSR, and affine version}
\label{sec:pulmonary}

We identify the set of bit \{0, 1\} with the two element field \bbf2.
This means that every arithmetic operation is done modulo 2.  A
$b$-bit register or memory is identified with a horizontal
vector in $\bbf2^b$, and $+$ denotes the sum as vectors (i.e.,
bit-wise exclusive or). We consider an array of $b$-bit integers of
size $N$ in
computer memory as the vector space $(\bbf2^{b})^N$.

An LFSR method is to generate a sequence $\mathbf{w_0}$,$\mathbf{w_1}$,
$\mathbf{w_2},...$ of elements $\bbf2^b$ by a recursion
\[ \mathbf{w}_{i+N} = g(\mathbf{w}_{i}, ..., \mathbf{w}_{i + N-1}), 
\quad (i=0,1,2,\ldots)
\]
where $g$ is an $\bbf2$-linear map $(\bbf2^{b})^N \rightarrow
\bbf2^b$.  In the implementation, this recursion is computed by using
an array \texttt{W[0..N-1]} of $N$ word of $b$-bit size, by the
simultaneous substitutions

\begin{multline*}
    \texttt{W[0]} \leftarrow \texttt{W[1]},\ 
    \texttt{W[1]} \leftarrow \texttt{W[2]}, \ldots,
    \texttt{W[N-2]} \leftarrow \texttt{W[N-1]}, \\  
    \texttt{W[N-1]} \leftarrow
    g(\texttt{W[0]},\ldots,\texttt{W[N-1]}). 
  \end{multline*}

The first $N-1$ substitutions shift the content of the array, hence
the name of LFSR.  Note that in the implementation we may use an
indexing technique to avoid computing these substitutions, see
\cite[P.28 Algorithm A]{knuth:bible}.  Before starting the generation,
we need to set some values to the state array, which is called the
initialization.

Mersenne Twister\cite{MT} (MT) is an example with
\[
g(\mathbf{w}_0,\ldots,\mathbf{w}_{N-1})=(\mathbf{w}_0|\mathbf{w}_1)A + 
\mathbf{w}_M,
\]
where $(\mathbf{w}_0|\mathbf{w}_1)$ denotes the concatenation of the
$32-r$ most significant bits (MSBs) of $\mathbf{w}_0$ and the $r$
least significant bits (LSBs) of $\mathbf{w}_1$, $A$ is a $(32\times
32)$-matrix for which the multiplication $\mathbf{w} A$ is computable
by a few bit-operations, and $M$ is an integer ($1 < M < N$).  Its
period is $2^{32N-r}-1$, chosen to be a Mersenne prime.  To obtain a
better equidistribution property, MT transforms the sequence by a
suitably chosen $(32\times 32)$ matrix $T$, namely, MT outputs
$\mathbf{x}_0 T , \mathbf{x}_1 T, \mathbf{x}_2 T, \ldots$ (called
tempering).

%LFSR has a problem about slow recovery from the status 
%which have many zero bits and little one bits \cite[\S 7]{well}.

A Pulmonary LFSR method is to generate a sequence
$\mathbf{w_0}$,$\mathbf{w_1}$, $\mathbf{w_2},...$ of elements
$\bbf2^b$ by a recursion
\begin{eqnarray}
  \mathbf{w}_i &=& g(\mathbf{w}_{i-N+1}, ..., \mathbf{w}_{i-1},
  \mathbf{u}_{i-1}), \label{eq:recursion} \\
  \mathbf{u}_i &=& h(\mathbf{w}_{i-N+1}, ..., \mathbf{w}_{i-1},
  \mathbf{u}_{i-1}). \label{eq:lung}
\end{eqnarray}
where $g$ and $h$ are $\bbf2$-linear maps $(\bbf2^{b})^N \rightarrow
\bbf2^b$ and $\mathbf{w}_i, \mathbf{u}_i \in \bbf2^b$.  In the
implementation, $\mathbf{w}_i$'s are kept in an array
\texttt{W[0..N-1]}, and $\mathbf{u}_i$
is (expected to be) kept in a register of
CPU, which is called the {\em lung}. We denote the register
by \texttt{U}. The first line (\ref{eq:recursion})
renews the array \texttt{W[0..N-1]}, and the second line (\ref{eq:lung}) renews
the register (lung) \texttt{U}.
The idea of Pulmonary LFSR appeared in the talk of Hiroshi
Haramoto in MCM 2005, and used in WELL PRNG\cite{WELL} in 2006.
The lung realizes a short feedback loop, which improves
some measures of randomness such as higher dimensional 
equidistributions and the density of nonzero coefficients
in the characteristic polynomial.

\subsection{Affinity introduced by the constant part}
A new difficulty appeared in dSFMT is that each component
of the array \texttt{W[0..N-1]} has fixed value
\texttt{0x3ff} in the 12 MSBs through the generation.
We may treat this part by bit-masking, but it leads to
slow-down. Keeping these 12 constant bits makes it difficult
to use the standard technique
to analyze the property of the generated sequence,
such as the period. Our solution to this difficulty 
is (a) to exclude the constant part of the array
from the state space, and (b) to consider an affine
state transition function.

More concretely, let $\mathbf{w}_{i}'$ denote the
lower 52-bit of $\mathbf{w}_i$. Since the upper 12-bit
is a constant, the recursion
formula (\ref{eq:recursion}), (\ref{eq:lung})
can be described by
\begin{eqnarray}
  \mathbf{w}_i' &=& g'(\mathbf{w}_{i-N+1}', ..., \mathbf{w}_{i-1}',
  \mathbf{u}_{i-1}), \label{eq:recursion-dash} \\
  \mathbf{u}_i &=& h'(\mathbf{w}_{i-N+1}', ..., \mathbf{w}_{i-1}',
  \mathbf{u}_{i-1}). \label{eq:lung-dash}
\end{eqnarray}
Here, it is easy to see that the linearity of $g$ (resp.\ $h$)
implies the affinity of $g'$ (resp.\ $h'$). (Here affine means
linear plus a constant.)

We make a model of this generator by an automaton.
Let $b_w$ denote the number of variable bits 
in each \texttt{W[i]} (52 in the above case), 
and $b_u$ denote the number of bits in the 
lung \texttt{U}.
Such a pulmonary LFSR (precisely, not linear but affine)
is considered as an automaton, with the state space 
$S=\bbf2^{b_u + b_w \times (N-1)}$.
The state transition function $F: S \to S$ is given by
\begin{equation*}
  \begin{split}
    (\mathbf{w}_0', &\ldots,\mathbf{w}_{N-2}', \mathbf{u}_0) \\
    &\mapsto 
    (\mathbf{w}_1',\ldots,\mathbf{w}_{N-2}',
    g'(\mathbf{w}_0',\ldots,\mathbf{w}_{N-2}', \mathbf{u}_0),
    h'(\mathbf{w}_0',\ldots,\mathbf{w}_{N-2}', \mathbf{u}_0)).
  \end{split}
\end{equation*}
As a $b_w$-bit vector generator (i.e., removing
the constant bits), the output function is 
\[
  o: S \to {\bbf2}^{b_w}; \quad
  (\mathbf{w}_0', \ldots, \mathbf{w}_{N-2}', \mathbf{u}_0) 
  \mapsto \mathbf{w}_0'.
\]

%We shall consider the variable bits in the array and the lung
%as the state space of the PRNG.
Now, both $F$ and $o$ are not linear
but affine. Namely, they have a form of 
$x \mapsto Ax+c$ where $x$ is a vector, $A$ is an
$\mathbb{F}_2$ matrix, and $c$ is a constant vector.
(If $c=0$, it is linear.)

%%%%%%%%%%%%%%%%%%%%
\subsection{Computation of the Period}
\label{sec:period}
%To assure the period of PRNG, we used Mersenne prime\cite{MT}.
If the transition function $F:S \to S$ is linear, then standard
methods compute its period. Let $f$ denote the linear part of $F$,
namely, put $c:=F(0)$ and 
\begin{equation}
F(x) = f(x) + c
\end{equation}
with linear $f: S \to S$. 
If $F$ has a fixed point
$F(s)=s$, then $F(x-s)=f(x-s)+c=f(x)-s$, and
consequently $F^n(x-s)=f^n(x)-s$.
Thus, for the state transition $x_0,x_1,x_2,\ldots$ by $F$,
its translation $x_0+s, x_1+s, \ldots$ by the constant $s$
is obtained by the linear state transition $f$, hence can be analyzed
by the existing methods. This solves the affinity problem,
since the property on randomness is essentially
unchanged by the translation.

The equation $F(s)=s$ is equivalent to $(f-\textrm{Id})(s)=c$.
Thus, a fixed point exists 
if the characteristic polynomial $\chi_f$ of $f$ 
does not have 1 as a root, 
in particular if irreducible with degree $\geq 2$.

However, this is not the case for dSFMT, where 
$\chi_f$ is reducible. One main difficulty in 
computing the period lies in the factorization of
$2^n-1$. If $\chi_f$ is irreducible, then the 
possible maximum period is $2^{\dim S}-1$. 
To certificate the period, we need the factorization 
of this number. For this, $\dim S$ must be not too
large (say, $<2000$), or otherwise, $\dim S$ must be a Mersenne
exponent (i.e. $2^{\dim S}-1$ itself is a prime:
such a prime is called a Mersenne prime.)

One way to avoid this difficulty is to adjust $\dim S$
to be a Mersenne prime by discarding (i.e., not using in the feedback function)
some specific bits from the array \texttt{W}, such as in 
MT and WELL\cite{WELL}.
 
SFMT adopted another method to avoid the integer factorization, the
reducible transition method (RTM), which uses a reducible
characteristic polynomial with a large primitive factor.  This idea
appeared in somewhat different purposes in 
\cite{FUSHIMI90}\cite{BRENT}\cite{BRENT-PRIM}.
RTM in our context means to find a linear transition function $f:S \to S$
that has decomposition $S=V_p\oplus V_r$
by $f$-invariant subspaces, where $V_p$ has 
a Mersenne exponent dimension $p$, and the restriction 
$f_p$ of $f$ to $V_p$ has the maximal period $2^p-1$.
The rest $V_r$ has the dimension $r < p$, and thus
the period of $f$ is at least the period of $f_p$,
and the high dimensional equidistribution is 
better than or equal to that of $f_p$ (see \cite{SFMT}).
Thus, we can obtain the lower bound of the period
and the dimension of equidistribution of $f$ by 
those of $f_p$, and for the latter, the period certification
is easy (see \cite[\S3.2.2]{knuth:bible}).
RTM needs not to discard $r$ bits at each generation, 
so at the generation stage it is faster than discarding 
methods. 

The new generator dSFMT uses this RTM, namely reducible $\chi_f$.
Although the affine transition function $F$ may not have
a fixed point, its restriction to $V_p$ does have:
if $c=c_p\oplus c_r$ and $x=x_p\oplus x_r$ are
the decompositions along $V_p\oplus V_r$, then
\begin{equation}\label{eq:decomp-F}
F(x)=f(x)+c=(f_p(x_p)+c_p) \oplus (f_r(x_r)+c_r):=F_p(x_p)\oplus F_r(x_r).
\end{equation}
Thus, the state transition $F$ is a direct sum of affine transitions
$F_p: V_p \to V_p$ and $F_r: V_r \to V_r$. Since $p>1$ and
$f_p$ is irreducible, $F_p$ has a fixed point as proved above.
Then, we can compute the period and equidistribution 
property with respect to $f_p$, which are equal to 
those for $F_p$, giving lower bounds for those for $F$.

We explain how to choose parameters.
For the linear transition function, the method is 
described in \cite{SFMT}, so they are only briefly 
recalled.
%just sketching show how to search an $f$ such that 
%$\chi_f$ has an irreducible $f_p$
%(cf. \cite{SFMT} which section). 
Let $p$ be a Mersenne exponent, and %$N:=\lceil p/b_w \rceil$.
$N$ be the smallest length of the array such that
the dimension of the state space 
$S=\bbf2^{b_u + b_w \times (N-1)}$
is greater than or equal to $p$. Thus, 
$r:=\dim S - p < b_w$ holds.

We randomly choose parameters for the recursion 
(\ref{eq:recursion-dash}) and
(\ref{eq:lung-dash}). Let $F:S \to S$ be the 
corresponding affine transition function, and $f:S \to S$ be
its linear part. We compute the characteristic
polynomial $\chi_f(t)$ by using Berlekamp-Massey algorithm, and
check whether it decomposes to 
\[
\chi_f=\phi_p \phi_r
\]
where $\phi_p$ is a primitive polynomial of degree $p$
and $\phi_r$ is a polynomial of degree %$r = wN-p$.
$r:=\dim S -p < b_w$. We assume $r<p$, which is natural
in our context where $p$ is large.
%and then check whether 
%it has a desired irreducible component.
%Fix a linear basis $B$ of $S$, 
%and for a $b \in B$, we compute the state transition 
%$b, f(b), f^2(b), \ldots$. Fix a bit in the state space,
%and compute the minimal polynomial $\phi_b(t)$ 
%of the bit sequence with respect to these transitions,
%by the Berlekamp-Massey Algorithm. 
%(Note that a direct computation of $\det(tI-f)$ is 
%prohibitedly slow, compared to the Berlekamp-Massey
%algorithm.)
%Then $\phi_b(t)$ divides $\chi_f(t)$. If the degree
%of $\phi_b(t)$ is equal to $\dim S$, then $\phi_b(t)$
%is $\chi_f(t)$. If not, we compute $\phi_{b'}$ for
%another $b' \in B$, and take the least common multiple (LCM) with
%$\phi_b(t)$. If its degree is equal to $\dim S$, we have
%$\chi_f(t)$. We iterate this for different element in $B$
%until the least common multple reaches to $\chi_f(t)$ or
%elements of $B$ are exhausted. In the latter case, we abondon
%the parameter.
%(One can easily show that the LCM of $\phi_b(t)$
% for all $b\in B$ and all bit in $S$ is equal to the minimal 
% polynomial of $f$, hence may not coinside with $\chi_f(t)$).
%To find a desired irreducible factor in $\chi_f(t)$,
%we use a sieve to divide out $\chi_f$ by
%all factors of small degree,
%until $\chi_f$ turns out to have no irreducible factor of degree $p$, 
%or it has a (possibly reducible) factor of degree $p$.  In the latter
%case, the factor is passed to the primitivity test described in
%\cite[\S3.2.2]{knuth:bible}. 
%
%If it passes, we found a parameter with a period certification.
%We have already computed a factorization
%\[
%\chi_f=\phi_p \phi_r,
%\]
%
Then these two factors are coprime, and extended Euclidean
algorithm computes polynomials $a(t),b(t)$.
\[
a(t)\phi_p + b(t)\phi_r = 1.
\]
It is standard in the linear algebra that 
$P_p = b(f)\phi_r(f)$ and $P_r=a(f)\phi_p(f)$
are projectors giving the decomposition into $f$-invariant subspaces
\[
S=V_p \oplus V_r:= \mathrm{Im}P_p \oplus \mathrm{Im}P_r \quad (\dim V_p=p, \ \dim V_r=r).
\]
The characteristic polynomial of 
the restriction $f_p$ of $f$ to $V_p$ is $\phi_p(t)$, and
that of the restriction $f_r$ to $V_r$ is $\phi_r(t)$. 
For any state $s \in S$, we denote $s=s_p+s_r$ for the corresponding
decomposition with $s_p \in V_p$ and $s_r \in V_r$.
Then, the $k$-th state $f^k(s)$ is equal to
$f_p^k(s_p) + f_r^k(s_r)$.

% This implies that the automaton 
% is equivalent to the sum of two automata $f_p:V_p \to V_p$ and
% $f_r: V_r \to V_r$. To combine two linear automata by sum is 
% well-studied as combined Tausworthe generators or combined LFSRs, 
% see \cite{CLT} \cite{COMBTAUS} \cite{COMBLFSR}.
% Their purpose is to obtain a good PRNG from several simple generators,
% which is different from ours.

The period length of the state transition by $f$ 
is the least common multiple
of that started from $s_p$ and that started from $s_r$. Hence, 
if $s_p \neq 0$, then the period is a nonzero multiple of $2^p-1$.
To assure that $s_p \neq 0$, we look some number of bits in the state
space $S$ more than $r=\dim V_r$ bits. For example,
we pick one of \texttt{W[i]} or \texttt{U}, say \texttt{U}.
By looking at only the bits in \texttt{U}, 
we have a projection $\pi:S \to V_U$, where we assume $\dim V_U > r$.
Now the image $\pi(V_r) \subset V_U$ is a proper subspace.
If we equip the standard inner product in $V_U$, then 
there is a nonzero vector which is orthogonal to $\pi(V_r)$.
We call such a vector {\em the period certification vector} (PCV).
Such vector can be obtained by solving a linear equation,
representing the orthogonality to all $\phi_p(f)(b)$
for $b$ moves in a fixed basis of $S$.
%dimension is greater than that of $V_r$, i.e, one of $w_i$s or $u$.
%Let $V_w$ is this subspace, and $V_{wr} = V_w \cap V_r$.  We can get
%the basis of $V_{wr}$ by applying $\phi_p(f)$ to randomly selected $s
%\in S$, and check in-dependency of the result vector in $V_{wr}$. Then
%we can get the basis of orthogonal space $V_{wo}$ of $V_{wr}$ in $V_w$
%by linear algebra. 
%??? the above seems to be wrong, V_w is not a subspace but a quotient
%space.
The inner product of PCV and any vector in $\pi(V_r)$ is zero.
Hence, if a state $s \in S$ has
non-zero inner product $\mathrm{PCV}\cdot \pi(s)=1$, 
then it implies that $s \notin V_r$, and thus $s_p \neq 0$,
which assures the period at least $2^p-1$ for $f$.
Note that this inner product is taken in $V_U$, i.e., looking
at the bits in \texttt{U} of $s$. 
If the inner product happens to be 0, 
then change one bit in $\pi(s)$, where PCV has 1, 
so that the inner product becomes one.
In sum, the initial state can not be chosen arbitrarily:
one bit in \texttt{U} is computed from the rest bit in \texttt{U},
to assure the period being a multiple of $2^p-1$.

Now we treat the affine case.
Consider the decomposition of the state transition function
$$
F(x_p\oplus x_r)=
(f_p(x_p)+c_p) \oplus (f_r(x_r)+c_r),
$$
as in (\ref{eq:decomp-F}).
Projectors $P_p$, $P_r$ compute $c_p$ and $c_r$.
Since $\phi_p$ is irreducible, there is a fixed point $v \in V_p$
with $F_p(v)=f_p(v)+c_p=v$. It is
efficiently computed by using the inverse polynomial
$\xi(t) \mmod \phi_p$ of $(1 - t) \mmod \phi_p$,
since $v:=\xi(f)(c_p)$ gives the solution.

%  $\phi_p$ is a characteristic
% polynomial of $V_p$ and is irreducible,
% % therefore $f_p$ does not have
% %eigenvalue 1, this means $f'_p$ have fix point.
% therefore we can calculate
% $a(t), b(t) \in \bbf2[t]$ using extended Euclid method such that:
% \[
% a(t)\phi_p(t) + b(t)(t - 1) = 1,
% \]
% then $b(t)$ is $(t - 1)^{-1} \mmod \phi_p(t).$ Now we get
% $(f_p -\textrm{Id}_{V_p})^{-1}$. Let $z := (f_p -\textrm{Id}_{V_p})^{-1}(c_p)$
% then $f_p(z) = z.$ 

%When affine function has a fix point $v_f$, then
% \begin{eqnarray*}
%   f'_p(z) &=& f_p(z) + c_p = z \\
%   c_p &=& z - f_p(z) \\
%   f'_p(s) &=& f_p(s) + z - f_p(z) \\
%   f'_p(s) - z &=& f_p(s - z).
% \end{eqnarray*}
%\begin{eqnarray*}
%  f_{ap}(s) - v_f &=& f_p(s - v_f) \\
%  f_{ap}^n(s) - v_f  &=& f_p^n(s - v_f) 
%\end{eqnarray*}
The period of the outputs with respect to 
the affine transition $F$ with initial 
state $s$ is bounded from below
by that of $F_p$ with $s_p$ (since the latter being a Mersenne prime,
it is coprime to that of $F_r$ for $r<p$).
As stated in the beginning of this subsection,
the state transition of $F_p$ becomes the state transition 
by $f_p$ after the translation of state vectors by adding $v$. 
Thus, for the period certification, it suffices to 
show that $s + v \notin V_r$. Using the projection 
$\pi: S \to V_U$, it suffices to keep $\pi(v)$ (not whole $v$),
and compute $(\pi(s) + \pi(v))\cdot \mathrm{PCV}$, 
and invert one bit in $\pi(s)$ if the inner product is zero, as 
explained above. All these computations can be done
inside \texttt{U} in the initialization stage, which
is not time consuming. 

%To assure the period, we subtract the fix point $v_f$ from the initial state
%$s_0$ first, then check if the result state is not in $V_r$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Computation of the dimension of equidistribution}
\label{sec:DE}
We briefly recall the definition of dimension of 
equidistribution (cf. \cite{CLT}\cite{COMBTAUS}\cite{SFMT}).
The version used here and its back ground are described in \cite{SFMT}. 
\begin{definition}\label{def:DE}
Consider a periodic sequence with period $P$
\[
\chi:=\mathbf{x}_0, \mathbf{x}_1, \ldots,
 \mathbf{x}_{P-1}, \mathbf{x}_P=\mathbf{x}_0, \ldots
\]
of $v$-bit integers.
Define the $k$-window multi-set of $\chi$
as
\[
W_k(\chi):=
\{(\mathbf{x}_i, \mathbf{x}_{i+1}, \ldots, \mathbf{x}_{i+k-1}) | 
i =0,1,\ldots, P-1\},
\]
where the multiplicity is counted. 
For a positive integer $m$,  
$m\cdot \bbf2^{vk}$ denote the multiset
consisting of every element of $\bbf2^{vk}$ with
multiplicity $m$. 
If there is an $m$ such that $W_k(\chi)$ is close
to $m\cdot \bbf2^{vk}$, namely, suppose that
$W_k(\chi) \subset m\cdot \bbf2^{vk}$
and the ratio of the complement 
$$r:=(\#(m \cdot \bbf2^{vk})-\#(W_k(\chi))) /\#(m \cdot \bbf2^{vk})$$
is ``small,'' 
then $\chi$
is said to be {\em $k$-dimensionally equidistributed}.
The largest value of such $k$ is called the dimension 
of equidistribution (DE).
\end{definition}
Here, ``small'' means less than or equal to $2^{-p}$, where $p$ 
is the Mersenne exponent considered in the PRNG. 

For a $b$-bit integer sequence, its {\em dimension of 
equidistribution at $v$-bit accuracy} $k(v)$
is defined as the DE of the $v$-bit sequence, obtained by extracting
the $v$ MSBs from each of the $b$-bit integers.
If the defect ratio is $1/(P+1)$, 
then there is an upper bound 
$k(v) \leq \lfloor \log_2 (P+1) / v \rfloor$,
and their gap $d(v)$ is 
called the dimension defect at $v$ of the sequence,
and their sum $\Delta$ over $v=1,\ldots,b$ is called
the total dimension defect, namely: 
\[
d(v):=\lfloor \log_2 (P+1) / v \rfloor -k(v) 
\mbox{ and } \Delta:=\sum_{v=1}^b d(v).
\]
%The summation of all the dimension defects at
%$1 \leq v \leq w$ is called the total dimension defect, 
%denoted by $\Delta$.
% We may compute $k(v)$ by standard linear algebra.
% We used a more efficient algorithm based on 
% a weighted norm,
% %{\em weighted lattice method} to compute $k'(v)$,
% generalizing \cite{CLT}. This will be written 
% somewhere else,
% because of lack of space. HARASE

In the linear transition case, $k(v)$ is
efficiently computed by lattice method \cite{CLT}.
In the affine state transition case, if there is a
fixed point, then $k(v)$ is unchanged when
the affine transition function 
and the affine output function are replaced with their linear parts,
by translation arguments.

In the RTM case, $k(v)$'s for the generator restricted to 
the transition $F_p: V_p \to V_p$ and the output
function $o|_{V_p}$ gives a lower bound of $k(v)$'s of the 
whole generator (see \cite{SFMT}). Accordingly, we define $k(v)$ of
RTM by $k(v)$ with respect to $V_p$ with period $2^p-1$. 
Since the fixed point exists for $F_p$, computation reduces to the linear case.

%There is a difficulty in computing $k(v)$ when 
%a 128-bit vector generator is used as a 32-bit 
%(or 64-bit) vector generator. This is solved by
%using weighted norm (see \cite{SFMT}\cite{thesis:saito}).

% SFMT generates a sequence
% $\mathbf{x}_0, \mathbf{x}_1, \mathbf{x}_2, \ldots$ of 128-bit integers. 
% Then, they are converted to a sequence of 32-bit integers
% $\mathbf{x}_0[0], \mathbf{x}_0[1], \mathbf{x}_0[2], \mathbf{x}_0[3], \mathbf{x}_1[0], \mathbf{x}_1[1],\ldots$,
% where 
% $\mathbf{x}[0]$ is the 32 LSBs of $\mathbf{x}$, 
% $\mathbf{x}[1]$ is the 33rd--64th bits,
% $\mathbf{x}[2]$ is the 65rd--96th bits,
% and $\mathbf{x}[3]$ is the 32 MSBs. 
% %(This is called the 
% %little-endian system, see 
% %\cite{wiki:endian}).
% %for the notion of endianness, 
% %and \S\ref{sec:portability} for
% %an implementation in a big-endian system). 

% Then, we need to modify the model automaton
% as follows.
% The state space is $S':=S \times \{0,1,2,3\}$,
% the state transition function $f':S' \to S'$ is
% $$
% f'(s,i):=
% \left\{
% \begin{array}{cl}
% (s, i+1) & (\mbox{ if $i<3$}), \\
% (f(s), 0) & (\mbox{ if $i=3$}) \\
% \end{array}
% \right.
% $$
% and the output function is 
% $$o': S' \to \bbf2^{32},\  ((\mathbf{w}_0,\ldots,\mathbf{w}_{N-1}),i) \mapsto \mathbf{w}_0[i].$$

% We fix $1\leq v \leq w$, and let $o_k(s,i)$ be the $k$-tuple
% of the $v$ MSBs of the consecutive $k$-outputs from 
% the state $(s,i)$.
% \begin{proposition}
% Assume that $f$ is bijective.
% Let $k'=k'(v)$ denote the maximum $k$ 
% such that 
% \begin{equation}\label{eq:chi-k-i}
% %o_k(-,i): V_p \subset S \to \bbf2^{kv}, \quad s \mapsto o_k(s,i)
% o_k(-,i): V_p \to \bbf2^{kv}, \quad s \mapsto o_k(s,i)
% \end{equation}
% are surjective for all $i=0,1,2,3$. 
% %Take the initial state $s$ satisfying $s_p \neq 0$.
% Take an initial state $s$ satisfying $s_p \neq 0$.
% Then, the 32-bit output sequence is at least $k'(v)$-dimensionally
% equidistributed with $v$-bit accuracy with defect ratio
% $2^{-p}$.

% Moreover, if $4 < k'(v)+1$, then  
% for any initial state with $s=s_p \neq 0$
% (hence $s_r=0$), the dimension of equidistribution
% with defect ratio $2^{-p}$ is exactly $k'(v)$.
% \end{proposition}
% \begin{proof}
% Take $s \in S$ with $s_p \neq 0$. Then, the 
% orbit of $s$ by $f$ has the form of
% $(V_p - \{0\}) \times U \subset V_p \times V_r$,
% since $p>r$ and $2^p-1$ is a prime.
% %Since the first component of the product has
% %odd order, the orbit of $f'$ has the form of
% %$(V_p - \{0\}) \times U' \times \{0,1,2,3\} \in S$.
% The surjectivity of the linear mapping $o_{k'}(-,i)$
% implies that the image of 
% $$
% o_{k'}(-,i): V_p \times U \to \bbf2^{kv}
% $$
% is $m\cdot \bbf2^{kv}$ as a multi-set for some $m$.
% The defect comes from $0 \in V_p$, whose ratio
% in $V_p$ is $2^{-p}$. Then the first statement follows,
% since $W_{k'}(\chi)$ is the union of the images
% $o_{k'}(-,i)((V_p-\{0\})\times U)$ for $i=0,1,2,3$.

% For the latter half, we define
% $L_i$ as the multiset of the image of 
% $o_{k'+1}(-,i): V_p \to \bbf2^{(k'+1)v}$.
% Because of $s_r=0$, we have $U=\{0\}$, and
% the union of $(L_i-\{0\})$ $(i=0,1,2,3)$ as a multi-set is 
% $W_{k'+1}(\chi)$. If the sequence is $(k'+1)$-dimensionally
% equidistributed, then the multiplicity of
% each element in $W_{k'+1}(\chi)$ is at most
% $2^p\times 4/ 2^{(k'+1)v}$.

% On the other hand, the multiplicity of 
% an element in $L_i$ is equal to 
% the cardinality of the kernel of $o_{k'+1}(-,i)$.
% Let $d_i$ be its dimension. Then by the dimension theorem,
% we have $d_i \geq p-(k'+1)v$, and the equality
% holds if and only if $o_{k'+1}(-,i)$ is 
% surjective.
% Thus, if there is a nonzero element 
% $x \in \cap_{i=0}^3{L_i}$, then its multiplicity
% in $W_{k'+1}(\chi)$ is no less than 
% $4 \times 2^{p-(k'+1)v}$, and since
% one of $o_{k'+1}(-,i)$ is not surjective
% by the definition of $k'$, its multiplicity
% actually exceeds $4 \times 2^{p-(k'+1)v}$,
% which implies that the sequence is not
% $(k'+1)$-dimensionally equidistributed, and
% the proposition follows. Since the codimension 
% of $L_i$ is at most $v$, 
% that of $\cap_{i=0}^3{L_i}$ is at most $4v$.
% The assumed inequality on $k'$ implies the existence
% of nonzero element in the intersection.
% %
% %Since the codimension of 
% %each $L_i$ is at most $v$, the codimension of
% %$\cap_{i=0}^3{L_i}$ is at most $4v$. The inequality
% %in the assumption implies that there are at least 
% %two nonzero vectors $x,y \in \cap_{i=0}^3{L_i}$.
% %Now the inverse image of $x$ by $o_{k'+1}(-,i)$
% %has the same cardinality with its kernel,
% %hence $2^{p-\dim L_i}\geq 2^{p-(k'+1)v}$.
% %
% %If $W_{k'+1}(\chi)$ is $(k'+1)$-dimensionally
% %equidistributed, then the inverse image of
% %
% \end{proof}

% The dimension of equidistribution $k(v)$ depends on 
% the choice of the initial state $s$. The above 
% proposition implies that $k'(v)$ coincides 
% with $k(v)$ for the worst choice of $s$ under the condition 
% $s_p \neq 0$. Thus, we adopt the following definition
% (analogously to $t_l$ in \cite{COMBTAUS}).

% \begin{definition}\label{def:virtual}
% Let $k$ be the maximum such that
% (\ref{eq:chi-k-i}) is satisfied. We call this
% the dimension of equidistribution
% of $v$-bit accuracy, and denote it simply by $k(v)$.
% We have an upper bound $k(v) \leq \lfloor p/v \rfloor$.

% We define the dimension defect at $v$
% %for SFMT19937 used as 32-bit integer generators
% by
% $$
% d(v):=\lfloor p/v \rfloor - k(v) 
% \mbox{ and } \Delta:=\sum_{v=1}^w d(v).
% $$
% \end{definition}
% We may compute $k(v)$ by standard linear algebra.
% We used a more efficient algorithm based on 
% a weighted norm,
% %{\em weighted lattice method} to compute $k'(v)$,
% generalizing \cite{CLT}. This will be written 
% somewhere else,
% because of lack of space. HARASE
%rather complicated mathematics, we omit it here
%(we plan another article for this). 

%The algorithm gives a (rather tight) 
%lower bound $k'(v)$ of $k(v)$ for each $v$, 
%and $k'(v) \leq \lceil 19937/v \rceil$ holds
%for SFMT19937.
%Consequently, we redefine the dimension defect for SFMT19937 by
%$$
%d(v):=\lceil 19937/v \rceil - k'(v) 
%\mbox{ and } \Delta:=\sum_{v=1}^w d(v).
%$$
%The meaning of $k'(v)$ and a justification for this 
%definition will be explained in the planned article.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
\label{sec:implement}

%The aim of this article is to design and to implement a fast floating
%point pseudorandom number generator with sufficient quality suitable
%for large scale scientific simulation. We decided to use 128-bit
%operation customizable in SIMD feature of modern CPUs because we 
%succeeded in SFMT.
As in SFMT, we decided to use 128-bit operations available in 
standard SIMD features for the efficient generation.
The proposed generator is named dSFMT (double precision
floating point SIMD-oriented Fast Mersenne Twister).
%is
%specialized in generating double precision floating point number in
%IEEE 754 format. 

Note that there is another dSFMT released in 
2007 from our web page\cite{web:SFMT}, 
but no corresponding article exists.
The generator proposed here is improved by
adopting the pulmonary LFSR and a more efficient recursion.
To avoid the confusion, we call the generator proposed 
in this paper as dSFMT ver. 2.

%%%%%%%%%%%%%%%%%%%%
\subsection{The recursion of dSFMT}
\label{sec:recursion}

dSFMT ver. 2 is a pulmonary LFSR, whose recursion formulas are
(\ref{eq:recursion})(\ref{eq:lung}) with
\begin{eqnarray}
  h(\mathbf{w}_0, \ldots , \mathbf{w}_{N-2}, \mathbf{u}_0)
  &=& \mathbf{w}_{0}A + \mathbf{w}_{M} + \mathbf{u}_{0}B, \label{eq:dsfmt}
  \\
  g(\mathbf{w}_0, \ldots , \mathbf{w}_{N-2}, \mathbf{u}_0)
  &=& \mathbf{w}_{0} 
  + h(\mathbf{w}_0, \ldots , \mathbf{w}_{N-2}, \mathbf{u}_0)C, \label{eq:dsfmt-lung}
\end{eqnarray}
where $\mathbf{w}_i$'s and $\mathbf{u}$ are
b(= 128) bit integers regarded as horizontal vectors
in $\bbf2^{128}$, and $A$, $B$, $C$ are linear transformations
described below, 
computable by a few SIMD operations. The number $b_w$ of variable bits
is $128-12\times 2=104$, while $b_u=128$.
\begin{itemize}
\item 
  $\mathbf{w} A := \mathbf{w} \stackrel{64}{<<} \textrm{SL1}$

  This notation means that $\mathbf{w}$ is regarded as two 
  64-bit memories, and $\mathbf{w} A$ is the result of the left-shift
  of each 64-bit by SL1 bits. There is such a SIMD operation in 
  Pentium SSE2, and can be emulated in PowerPC AltiVec SIMD.
  SL1 is a parameter with $12 \le \textrm{SL1} < 64$.

\item
  $\mathbf{u} B := \mathbf{u}\,\textrm{perm(4, 3, 2, 1)}$

  This notation means that $\mathbf{u}$ is regarded as four
  32-bit memories and $\mathbf{u}\,\textrm{perm(4, 3, 2, 1)}$ is
  the result of reverse the order of 32-bit block in 128-bit.
  The permutation can be done by one SIMD operation.

\item 
  $\mathbf{u} C := (\mathbf{u} \stackrel{64}{>>} 12) 
  + (\mathbf{u}\, \& \,\textrm{MASK})$

  The notation $\mathbf{u} \stackrel{64}{>>} 12$ means that
  $\mathbf{u}$ is regarded as two 64-bit memories and each
  right-shifted by 12 bit.  The notation $\&$ means 128-bit
  bitwise logical `\textbf{AND}' with a 128-bit constant vector \textbf{MASK}.
  MASK is a concatenation of two 64-bit vectors with 0s in the 12 MSBs 
  for both.

\end{itemize}
%The state vector
%is kept in an N elements array of computer memory, where
%$\mathbf{w}_0$, \ldots , $\mathbf{w}_{N-2}$ are 0th to (N-2)th element and
%$u$ is the last element. 

%Here is a piece of code to show the recursion written in C language.
%\begin{verbatim}
%    u[0] = (w0[0] << SL1) ^ wm[0] ^ (u0[1] >> 32) ^ (u0[1] << 32);
%    u[1] = (w0[1] << SL1) ^ wm[1] ^ (u0[0] >> 32) ^ (u0[0] << 32);
%    w[0] = w0[0] ^ (u[0] >> 12) ^ (u[0] & MASK[0]);
%    w[0] = w0[1] ^ (u[1] >> 12) ^ (u[1] & MASK[1]);
%\end{verbatim}
%where \texttt{\^} and \texttt{\&} means bitwise exclusive `OR' and
%`AND' respectively, every array is declared to have two unsigned
%64-bit integers and \texttt{w0} is for $w_0$, and so on. 
Fig.~\ref{fig:dsfmt} shows the recursion in a circuit-like diagram.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig-dsfmt.pdf}
  \caption{Diagram of dSFMT}
  \label{fig:dsfmt}
\end{figure}

Note that the recursion (\ref{eq:dsfmt})(\ref{eq:dsfmt-lung})
is linear, and constant \texttt{0x3ff} of IEEE 754 exponent part
does not appear.
The recursion is carefully selected so that once
the initial value $w_0,\ldots , w_{N-2}$ have \texttt{0x3ff} in their 12 MSBs,
then these constant parts are preserved through the recursion. 
This trick contributes to the generation speed, by avoiding
constants setting.

Table~\ref{tab:params} lists the parameters 
for dSFMT ver. 2 with various sizes.
Table~\ref{tab:pcv} lists the corresponding fixed points and period
certification vectors(PCV).

% We checked the following. 
% \begin{proposition}
% The period of SFMT19937 as a 128-bit integer generator is 
% a nonzero multiple of $2^{19937}-1$, if the 32 MSBs of 
% $\mathbf{w}_0$ are set to 
% the value {\tt 6d736d6d} in hexadecimal form.
% \end{proposition}

\begin{table}
  \begin{center}
    \caption{Parameter sets}
    \label{tab:params}
    \begin{tabular}{rrrrrr} \hline
      MEXP & $N$ & $M$ & SL1 & MASK(LOW) & MASK(HIGH) \\ \hline \hline
      521 & 5 & 3 & 25 & \texttt{0x000fbfefff77efff} 
      & \texttt{0x000ffeebfbdfbfdf} \\
      1279 & 13 & 9 & 19 & \texttt{0x000efff7ffddffee} 
      & \texttt{0x000fbffffff77fff} \\
      2203 & 21 & 7 & 19 & \texttt{0x000fdffff5edbfff} 
      & \texttt{0x000f77fffffffbfe} \\
      4253 & 41 & 19 & 19 & \texttt{0x0007b7fffef5feff} 
      & \texttt{0x000ffdffeffefbfc} \\
      11213 & 108 & 37 & 19 & \texttt{0x000ffffffdf7fffd} 
      & \texttt{0x000dfffffff6bfff} \\
      19937 & 192 & 117 & 19 & \texttt{0x000ffafffffffb3f} 
      & \texttt{0x000ffdfffc90fffd} \\ \hline
    \end{tabular}
  \end{center}
\end{table}

% $N$, the size of 128-bit array is 
% $\lceil (\textrm{MEXP} - 128) / 104 \rceil + 1$.
% Parameters $M$, SL1 and mask are randomly selected to fit the
% condition that $0 < M < N - 2$, $ 12 < \textrm{SL1}$ and 
% 12-bit of MSB of mask are all zero and the rest bits has many 1s.
% By trial and error, 
% we searched for a set of parameters of dSFMT,
% with the period being a multiple of Mersenne Prime
% and having good equidistribution properties.
% Taable~\ref{tab:params} shows some parameter sets.

%This value of $\mathbf{w}_0$ assures that $s_p\neq 0$,
%see \cite{PMT} for a way to find such a value.

\begin{table}
  \begin{center}
    \caption{Fix Points and Period certification vectors}
    \label{tab:pcv}
    \begin{tabular}{c|rr} \hline
      MEXP & \multicolumn{1}{c}{Fix Point} 
      & \multicolumn{1}{c}{PCV} \\ \hline \hline
      & \texttt{0xcfb393d661638469} & \texttt{0xccaa588000000000} \\
      521 & \texttt{0xc166867883ae2adb} &\texttt{ 0x0000000000000001} \\ \hline
      & \texttt{0xb66627623d1a31be} & \texttt{0x7049f2da382a6aeb} \\
      1279 & \texttt{0x04b6c51147b6109b} & \texttt{0xde4ca84a40000001} \\ \hline
      & \texttt{0xb14e907a39338485} & \texttt{0x8000000000000000} \\
      2203 & \texttt{0xf98f0735c637ef90} & \texttt{0x0000000000000001} \\ \hline
      & \texttt{0x80901b5fd7a11c65} & \texttt{0x1ad277be12000000} \\
      4253 & \texttt{0x5a63ff0e7cb0ba74} & \texttt{0x0000000000000001} \\ \hline
      & \texttt{0xd0ef7b7c75b06793} & \texttt{0x8234c51207c80000} \\
      11213 & \texttt{0x9c50ff4caae0a641} & \texttt{0x0000000000000001}\\ \hline
      & \texttt{0x90014964b32f4329} & \texttt{0x3d84e1ac0dc82880} \\
      19937 & \texttt{0x3b8d12ac548a7c7a} & \texttt{0x0000000000000001} \\ 
      \hline
    \end{tabular}
  \end{center}
\end{table}

% Most of application program needs floating point numbers $r$ in the range
% $0 \le r < 1$, then dSFMT ver.2 can also generate floating point numbers in
% the range $0 \le r < 1$ and $0 < r \le 1$. The conversion is just a simple
% subtraction between floating points, hence it is fast.
% Additionally, dSFMT supports to generate numbers in the range $0 < r < 1$.
% In this case, we need to set LSB of fraction part, hence this is little
% bit slower.

% In some cases, for example if you need floating points in the range $0
% \le r < 2\pi$ for trigonometric functions, you can use the number in
% the range $1 \le r < 2$ instead of the number in the range $0 \le r <
% 1$, because they indecates same value for trigonometric functions
% after multiplying $2\pi$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comparison of speed}\label{sec:comp-speed}
We compared two algorithms: MT19937, 64-bit MT19937, SFMT19937, dSFMT
ver.1 19937 and dSFMT ver.2 19937 with implementations using and
without using SIMD instructions. For MT and SFMT, `mask' means the
conversion by bit operation described in \S\ref{sec:floating} from 64
bit integer, % of two 32-bit integers,
and `$\times$ const' means the
conversion by multiplying $2^{-64}$. Note that original MT and SFMT
don't use `mask' conversion.

We measured the speeds for five different CPUs: Pentium M 1.4GHz,
Pentium IV 3GHz, core 2 duo 1.83GHz (32-bit mode, use 1 core), AMD
Athlon 64 3800+ (64-bit mode), and PowerPC G4 1.33GHz.  In returning
the random values, we used two different methods.  One is sequential
generation, where one double floating point random number is returned
for one call.  The other is block generation, where an array of random
double floating point numbers is generated for one call.  We used
Intel C Compiler for intel CPUs (Pentium M, Pentium IV, core 2 duo)
and GNU C Compiler for others (AMD Athlon, Power PC G4).

We measured the consumed CPU time in second, for $10^8$ generations of
floating point numbers in the range $[0, 1)$ to compare with other
generators.  More precisely, in case of the block generation, we
generate $10^5$ of floating point numbers by one call, and this is
iterated for $10^3$ times.  For sequential generation, the same $10^8$
floating point numbers are generated, one per call.  We used
the inline declaration {\tt inline} to avoid the function call.
Implementations without SIMD are written in INTERNATIONAL STANDARD
ISO/IEC 9899 : 1999(E) Programming Language-C, Second Edition (which
we shall refer to as C99 in the rest of this article), whereas those
with SIMD use some standard SIMD extension of C99 supported by the
Intel C compiler and GNU C Compiler.

Table~\ref{tab:speed-simd} summarises the speed comparison using SIMD
and Table~\ref{tab:speed-c} shows the speed comparison without using
SIMD.  64-bit MT is not listed in Table~\ref{tab:speed-simd}, because
we don't have SIMD version.  The first two lines list the CPU time (in
seconds) needed to generate $10^8$ floating point numbers, for a
Pentium-M CPU.  The first line lists the seconds for the
block-generation scheme.  The second line lists the seconds for the
sequential generation scheme. 

The result is clear: dSFMT ver. 2 is the fastest for all CPUs, all
returning methods, using SIMD and without using SIMD.

\begin{table}
  \begin{center}
    \caption{The CPU time (sec.) for $10^8$ generations using SIMD.}
    %of double precision
    %floating point numbers [0, 1) using SIMD feature.}
    \label{tab:speed-simd}
    \begin{tabular}{|ll|r|r|r|r|r|} \hline
      && dSFMTv2 & dSFMTv1 & MT & SFMT & SFMT \\
      && (new) & (old) & mask & mask & $\times$ const \\ \hline \hline
      Pentium M & blk & 0.626 & 0.867 & 1.526 & 0.928 & 2.636 \\
      1.4 Ghz & seq & 1.422 & 1.761 & 3.181 & 2.342 & 3.671 \\ \hline
      Pentium 4 & blk & 0.254 & 0.640 & 0.987 & 0.615 & 3.537 \\
      3 Ghz & seq & 0.692 & 1.148 & 3.339 & 3.040 & 3.746 \\ \hline
      core 2 duo & blk & 0.199 & 0.381 & 0.705 & 0.336 & 0.532 \\
      1.83GHz & seq & 0.380 & 0.457 & 1.817 & 1.317 & 2.161 \\\hline
      Athlon 64 & blk & 0.362 & 0.637 & 1.117 & 0.623 & 1.278 \\
      2.4GHz & seq & 0.680 & 0.816 & 1.637 & 0.763 & 1.623 \\ \hline
      PowerPC G4& blk & 0.887 & 1.151 & 2.175 & 1.657 & 8.897 \\
      1.33GHz & seq & 1.212 & 1.401 & 5.624 & 2.994 & 7.712 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\begin{table}
  \begin{center}
    \caption{The CPU time (sec.) for $10^8$ generations (without using SIMD).}
    %of double precision
    %floating point numbers [0, 1) using standard C (without using SIMD).}
    \label{tab:speed-c}
    \begin{tabular}{|ll|r|r|r|r|r|r|} \hline
      &  & dSFMT2 & dSFMT1 & MT 64 & MT & SFMT & SFMT \\
      &  &(new)&(old)& mask & mask & mask & $\times$ const \\ \hline\hline
      Pentium M & blk & 1.345 & 2.023 & 2.031 & 3.002 & 2.026 & 3.355 \\
      1.4 Ghz & seq & 2.004 & 2.386 & 2.579 & 3.308 & 2.835 & 3.910 \\ \hline
      Pentium 4 & blk & 1.079 & 1.128 & 1.432 & 2.515 & 1.929 & 3.762 \\
      3 Ghz & seq & 1.431 & 1.673 & 3.137 & 3.534 & 3.485 & 4.331 \\ \hline
      core 2 duo & blk & 0.899 & 1.382 & 1.359 & 2.404 & 1.883 & 1.418 \\
      1.83GHz & seq & 0.777 & 1.368 & 1.794 & 1.997 & 1.925 & 2.716 \\ \hline
      Athlon 64 & blk & 0.334 & 0.765 & 0.820 & 1.896 & 1.157 & 1.677 \\
      2.4GHz & seq & 0.567 & 0.970 & 1.046 & 2.134 & 1.129 & 2.023 \\ \hline
      PowerPC G4 & blk & 1.834 & 3.567 & 2.297 & 4.326 & 4.521 & 12.685 \\
      1.33GHz & seq & 1.960 & 2.865 & 4.090 & 5.489 & 5.464 & 9.110 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

For a reference, Table~\ref{tab:speed-other} shows the speed of other
generators. It is not a fair comparison, 
because dSFMT has 52-bit precision and other generators have 32-bit
precision only. Even though, dSFMT's sequential generation using standard
C (i.e. the slowest case) is faster than other generators, except xorshift128
\cite{XORSHIFT-MAR}.

\begin{table}
  \begin{center}
    \caption{The CPU time (sec.) for $10^8$ generations.}
    % of double precision floating point numbers [0, 1).
    % from 32 bit pseudorandom integers using standard C.}
    \label{tab:speed-other}
    \begin{tabular}{|l|r|r|r|r|} \hline
      & WELL1024 & WELL19937 & MT19937 & XORSHIFT128 \\ \hline
      Pentium M & 2.076 & 2.876 & 2.028 & 1.233 \\
      Pentium 4 & 1.626 & 2.031 & 1.232 & 1.023 \\
      core 2 duo & 1.165 & 1.913 & 1.032 & 0.653 \\
      Athlon 64 & 0.804 & 1.191 & 0.971 & 0.975 \\
      Power PC G4 & 2.947 & 7.524 & 3.082 & 2.267 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dimension of equidistribution}
\label{sec:equidistribution}
We calculated $d(v)$s for our generators, by using method described 
in \S~\ref{sec:DE}.

Table~\ref{tab:dd} lists the dimension defects $d(v)$ of dSFMT, for
Mersenne exponent (mexp) $= 521, 1279, 2203, 4253, 11213, 19937$ and
$v=1,2,\ldots, 52$.  The $d(v)$ for $1 \le v \le 22$ are very small. 
The larger mexp
seems to lead to the larger $d(v)$ for $v>22$. Still, the case mexp=19937 has 
total dimension defect $\Delta=2608$, which is smaller than $4188$ of
SFMT19937's 32-bit $\Delta$ and $6750$ of MT19937's 32-bit $\Delta$
(note that $\Delta$ tends to increase according to the increase of the bit size
of the generated numbers, by its definition).

\begin{table}
  \begin{center}
    \caption{$d(v)$ of 52-bit fraction part of dSFMTv2.}
    \label{tab:dd}
    \begin{tabular}{|r|rrrrrr||r|rrrrrr|} \hline
      & 521 & 1279 & 2203 & 4253 & 11213 & 19937 
      & & 521 & 1279 & 2203 & 4253 & 11213 & 19937 \\ \hline
      d(1) & 0 & 1 & 0 & 0 & 4 & 0 & d(27) & 0 & 0 & 1 & 1 & 33 & 4 \\
      d(2) & 0 & 1 & 1 & 0 & 0 & 1 & d(28) & 0 & 6 & 7 & 28 & 33 & 10 \\
      d(3) & 0 & 2 & 1 & 0 & 0 & 1 & d(29) & 1 & 5 & 7 & 23 & 28 & 67 \\
      d(4) & 0 & 0 & 0 & 0 & 1 & 1 & d(30) & 3 & 3 & 15 & 18 & 80 & 126 \\
      d(5) & 0 & 0 & 0 & 0 & 0 & 0 & d(31) & 2 & 6 & 13 & 15 & 68 & 107 \\
      d(6) & 0 & 1 & 1 & 0 & 1 & 0 & d(32) & 4 & 4 & 10 & 10 & 58 & 88 \\
      d(7) & 0 & 0 & 0 & 0 & 0 & 1 & d(33) & 6 & 12 & 25 & 43 & 120 & 220 \\
      d(8) & 0 & 0 & 0 & 0 & 0 & 1 & d(34) & 6 & 12 & 23 & 44 & 114 & 202 \\
      d(9) & 0 & 1 & 0 & 0 & 0 & 0 & d(35) & 5 & 11 & 21 & 40 & 105 & 185 \\
      d(10) & 1 & 0 & 0 & 0 & 0 & 0 & d(36) & 5 & 10 & 20 & 37 & 96 & 169 \\
      d(11) & 0 & 0 & 0 & 0 & 0 & 0 & d(37) & 5 & 9 & 18 & 33 & 88 & 155 \\
      d(12) & 0 & 0 & 0 & 0 & 0 & 0 & d(38) & 4 & 8 & 16 & 30 & 80 & 141 \\
      d(13) & 0 & 0 & 0 & 0 & 0 & 0 & d(39) & 4 & 7 & 15 & 28 & 72 & 128 \\
      d(14) & 0 & 0 & 0 & 0 & 0 & 1 & d(40) & 4 & 6 & 14 & 25 & 65 & 115 \\
      d(15) & 0 & 0 & 0 & 0 & 0 & 1 & d(41) & 3 & 6 & 12 & 22 & 58 & 103 \\
      d(16) & 0 & 0 & 0 & 0 & 0 & 1 & d(42) & 3 & 5 & 11 & 20 & 51 & 91 \\
      d(17) & 0 & 0 & 0 & 0 & 0 & 0 & d(43) & 3 & 4 & 10 & 17 & 45 & 80 \\
      d(18) & 0 & 0 & 0 & 0 & 0 & 0 & d(44) & 2 & 4 & 9 & 15 & 39 & 70 \\
      d(19) & 0 & 0 & 0 & 0 & 0 & 0 & d(45) & 2 & 3 & 7 & 13 & 34 & 60 \\
      d(20) & 1 & 0 & 0 & 0 & 0 & 0 & d(46) & 2 & 2 & 6 & 11 & 28 & 50 \\
      d(21) & 0 & 0 & 0 & 0 & 7 & 0 & d(47) & 2 & 2 & 5 & 9 & 23 & 41 \\
      d(22) & 0 & 0 & 0 & 0 & 0 & 134 & d(48) & 1 & 1 & 4 & 7 & 18 & 32 \\
      d(23) & 0 & 0 & 7 & 16 & 22 & 94 & d(49) & 1 & 1 & 3 & 5 & 13 & 23 \\
      d(24) & 0 & 1 & 3 & 9 & 19 & 58 & d(50) & 1 & 0 & 3 & 4 & 9 & 15 \\
      d(25) & 0 & 1 & 0 & 6 & 7 & 25 & d(51) & 1 & 0 & 2 & 2 & 4 & 7 \\
      d(26) & 0 & 0 & 0 & 0 & 0 & 0 & d(52) & 1 & 0 & 1 & 0 & 0 & 0 \\ \hline
      \multicolumn{8}{|l|}{total dimension defect $\Delta$} 
      & 73 & 135 & 291 & 531 & 1423 & 2608 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\begin{remark}
  The number of non-zero terms in $\chi_f(t)$ is an index measuring
  the amount of bit-mixing.  The column \textbf{weight} in the 
  Table~\ref{tab:weight} shows these numbers. These values are almost
  half of the degree of $\chi_f(t)$, larger than those of MT
  and WELL, which implies good bit-mixing.
\end{remark}

\begin{table}[h]
  \begin{center}
    \caption{The number of non zero term in $\chi_f(t)$}
    \label{tab:weight}
    \begin{tabular}{c|rrrrrr} \hline
      mexp & 521 & 1279 & 2203 & 4253 & 11213 & 19937 \\
      degree of $\chi_f(t)$ & 544 & 1376 & 2208 & 4288 & 11256 & 19992 \\
      weight & 273 & 673 & 1076 & 2233 & 5684 & 9756 \\ 
      ratio & 0.50 & 0.49 & 0.49 & 0.52 & 0.50 & 0.49 \\ \hline
    \end{tabular}
  \end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Concluding remarks}

We proposed PRNG specialized in generating double precision
floating point numbers. Using \bbf2-affine state transition
function, our generator makes IEEE 754 format floating point number
representations in the computer
memory. We discussed the theoretical base of this generator.

By considering architecture of modern CPUs and by trial and error, we
implemented double precision floating point SFMT (dSFMT) whose periods
are multiples of 
Mersenne primes $2^{521}-1$, $2^{1279}-1$, $2^{2203}-1$, $2^{4253}-1$, 
$2^{11213}-1$, $2^{19937}-1$, respectively.
Their generation is very fast, compared with existing generators.
Moreover, they have good equidistribution property.
These generators passed DIEHARD Battery of Tests of Randomness.\cite{diehard}

% %\subsection{Trade-off between speed and quality}
% It is difficult to measure the generation speed of a PRNG in a fair way,
% since it depends heavily on the circumstances. 
% The 
% WELL \cite{WELL} generators have the best possible dimensions of 
% equidistribution (i.e. $\Delta=0$)
% for various periods ($2^{1024}-1$ to $2^{19937}-1$).
% %If we use the function call to PRNG
% If we use the function call to the PRNG
% for each generation, then a large part of the CPU time
% is consumed for handling the function call, and in the 
% experiments in \cite{WELL} or \cite{XORSHIFT}, WELL 
% is not much slower than MT. On the other hand, if we avoid
% the function call, WELL is slower than MT for some CPUs, 
% as seen in Table~\ref{tab:speed}. 

% Since $\Delta=0$, WELL has a better quality than MT or SFMT
% in a theoretical sense. 
% However, one may argue whether this difference is 
% observable or not. In the case of an $\bbf2$-linear generator,
% the dimension of equidistribution $k(v)$ of $v$-bit accuracy
% means that
% there is no constant linear relation among the 
% $kv$ bits, but there exists a linear relation among
% the $(k+1)v$ bits, where $kv$ bits 
% ($(k+1)v$ bits) are taken from
% all the consecutive $k$ integers 
% ($k+1$ integers, respectively)
% by extracting the $v$ MSBs from each.
% However, the existence of a linear relation does not necessarily
% mean the existence of some observable bias.
% According to \cite{TESTWEIGHT}, it requires $10^{28}$
% samples to detect an $\bbf2$-linear relation with 
% 15 (or more) terms among 521 bits, by weight distribution test. 
% If the number of 
% bits is increased, 
% the necessary sample size is increased rapidly. Thus, it seems
% that $k(v)$ of SFMT19937 is sufficiently large, far beyond
% the level of the observable bias. 
% On the other hand, the speed of the generator is 
% observable.
% Thus, SFMT focuses more on the speed, for applications
% that require fast generations. 
% (Note: the referee pointed out that statistical
% tests based on the rank of $\bbf2$-matrix is sensitive to 
% the linear relations \cite{TESTU01}, 
% so the above observation is not necessarily true.)

% %\subsection{Trade-off between speed and portability}\label{sec:portability}
% There is a trade-off between the speed and portability.
% %We prepare (1) a standard C code of SFMT, which uses 
% We prepared (1) a standard C code of SFMT, which uses 
% functions specified in C99 only, (2) an optimized C code for
% Intel Pentium SSE2, and 
% (3) an optimized C code for PowerPC AltiVec. The optimized codes require
% %icl (Intel C Compiler) or gcc compiler with suitable options.
% the icl (Intel C Compiler) or gcc compiler with suitable options.
We had put and will keep the newest version of the codes 
in the web page \cite{web:SFMT}.

\section*{Acknowledgements}
This study is partially
supported by JSPS/MEXT Grant-in-Aid for Scientific Research
No.19204002, No.18654021, and JSPS Core-to-Core Program
No.18005.

\bibliographystyle{plain}
\bibliography{sfmt-kanren}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LocalWords:  MCQMC denormalized xxxx NaN xxxxx Hiroshi Haramoto MCM nw RTM tI
% LocalWords:  wN th wr wo PCV kv vk sl rrrrrrr MEXP fbfefff efff ffeebfbdfbfdf
% LocalWords:  ffddffee fbffffff fff fdffff edbfff fffffffbfe fffef feff fffd
% LocalWords:  ffdffeffefbfc ffffffdf dfffffff bfff ffafffffffb ffdfffc rr xcfb
% LocalWords:  xccaa xc ae adb xb da aeb xde xf ef fd cb ba xd caae uint IEC le
% LocalWords:  icl dSFMTv const blk Ghz mexp rrrrrr sfmt kanren equi LSB intel
% LocalWords:  crrrrrr ap ar xorshift Im dSFMT's
